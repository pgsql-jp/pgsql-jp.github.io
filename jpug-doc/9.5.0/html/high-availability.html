<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>第25章 高可用性、負荷分散およびレプリケーション</title><link rel="stylesheet" type="text/css" href="stylesheet.css" /><link rev="made" href="pgsql-docs@postgresql.org" /><meta name="generator" content="DocBook XSL Stylesheets V1.78.1" /><link rel="home" href="index.html" title="PostgreSQL 9.5.0文書" /><link rel="up" href="admin.html" title="パート III. サーバの管理" /><link rel="prev" href="continuous-archiving.html" title="24.3. 継続的アーカイブとポイントインタイムリカバリ（PITR）" /><link rel="next" href="different-replication-solutions.html" title="25.1. 様々な解法の比較" /><link rel="copyright" href="legalnotice.html" title="法的告知" /></head><body><div class="navheader"><table width="100%" summary="Navigation header"><tr><th colspan="3" align="center">第25章 高可用性、負荷分散およびレプリケーション</th></tr><tr><td width="20%" align="left"><a accesskey="p" href="continuous-archiving.html">戻る</a> </td><th width="60%" align="center">パート III. サーバの管理</th><td width="20%" align="right"> <a accesskey="n" href="different-replication-solutions.html">次へ</a></td></tr></table><hr /></div><div class="chapter" id="high-availability"><div class="titlepage"><div><div><h2 class="title">第25章 高可用性、負荷分散およびレプリケーション</h2></div></div></div><div class="toc"><p><strong>目次</strong></p><dl class="toc"><dt><span class="sect1"><a href="different-replication-solutions.html">25.1. 様々な解法の比較</a></span></dt><dt><span class="sect1"><a href="warm-standby.html">25.2. ログシッピングスタンバイサーバ</a></span></dt><dd><dl><dt><span class="sect2"><a href="warm-standby.html#standby-planning">25.2.1. 計画</a></span></dt><dt><span class="sect2"><a href="warm-standby.html#standby-server-operation">25.2.2. スタンバイサーバの動作</a></span></dt><dt><span class="sect2"><a href="warm-standby.html#preparing-master-for-standby">25.2.3. スタンバイサーバのためのマスタの準備</a></span></dt><dt><span class="sect2"><a href="warm-standby.html#standby-server-setup">25.2.4. スタンバイサーバの設定</a></span></dt><dt><span class="sect2"><a href="warm-standby.html#streaming-replication">25.2.5. ストリーミングレプリケーション</a></span></dt><dt><span class="sect2"><a href="warm-standby.html#streaming-replication-slots">25.2.6. レプリケーションスロット</a></span></dt><dt><span class="sect2"><a href="warm-standby.html#cascading-replication">25.2.7. カスケードレプリケーション</a></span></dt><dt><span class="sect2"><a href="warm-standby.html#synchronous-replication">25.2.8. 同期レプリケーション</a></span></dt><dt><span class="sect2"><a href="warm-standby.html#continuous-archiving-in-standby">25.2.9. スタンバイにおける継続的アーカイビング</a></span></dt></dl></dd><dt><span class="sect1"><a href="warm-standby-failover.html">25.3. フェールオーバ</a></span></dt><dt><span class="sect1"><a href="log-shipping-alternative.html">25.4. この他のログシッピングの方法</a></span></dt><dd><dl><dt><span class="sect2"><a href="log-shipping-alternative.html#warm-standby-config">25.4.1. 実装</a></span></dt><dt><span class="sect2"><a href="log-shipping-alternative.html#warm-standby-record">25.4.2. レコードベースのログシッピング</a></span></dt></dl></dd><dt><span class="sect1"><a href="hot-standby.html">25.5. ホットスタンバイ</a></span></dt><dd><dl><dt><span class="sect2"><a href="hot-standby.html#hot-standby-users">25.5.1. ユーザのための概説</a></span></dt><dt><span class="sect2"><a href="hot-standby.html#hot-standby-conflict">25.5.2. 問い合わせコンフリクトの処理</a></span></dt><dt><span class="sect2"><a href="hot-standby.html#hot-standby-admin">25.5.3. 管理者のための概説</a></span></dt><dt><span class="sect2"><a href="hot-standby.html#hot-standby-parameters">25.5.4. ホットスタンバイパラメータリファレンス</a></span></dt><dt><span class="sect2"><a href="hot-standby.html#hot-standby-caveats">25.5.5. 警告</a></span></dt></dl></dd></dl></div><span class="original"><!--$--> Changed-v1.29
 &lt;title&gt;High Availability, Load Balancing, and Replication&lt;/title&gt;
</span><br /><span class="original"><!--$-->
 &lt;indexterm&gt;&lt;primary&gt;high availability&lt;/&gt;&lt;/&gt;
 &lt;indexterm&gt;&lt;primary&gt;failover&lt;/&gt;&lt;/&gt;
 &lt;indexterm&gt;&lt;primary&gt;replication&lt;/&gt;&lt;/&gt;
 &lt;indexterm&gt;&lt;primary&gt;load balancing&lt;/&gt;&lt;/&gt;
 &lt;indexterm&gt;&lt;primary&gt;clustering&lt;/&gt;&lt;/&gt;
 &lt;indexterm&gt;&lt;primary&gt;data partitioning&lt;/&gt;&lt;/&gt;
</span><br /><a id="idp77138016" class="indexterm"></a><a id="idp77139072" class="indexterm"></a><a id="idp77139760" class="indexterm"></a><a id="idp77140464" class="indexterm"></a><a id="idp77141152" class="indexterm"></a><a id="idp77141840" class="indexterm"></a><p><span class="original"><!--$-->
  Database servers can work together to allow a second server to
  take over quickly if the primary server fails (high
  availability), or to allow several computers to serve the same
  data (load balancing).  Ideally, database servers could work
  together seamlessly.  Web servers serving static web pages can
  be combined quite easily by merely load-balancing web requests
  to multiple machines.  In fact, read-only database servers can
  be combined relatively easily too.  Unfortunately, most database
  servers have a read/write mix of requests, and read/write servers
  are much harder to combine.  This is because though read-only
  data needs to be placed on each server only once, a write to any
  server has to be propagated to all servers so that future read
  requests to those servers return consistent results.
</span><br />データベースサーバは共同して稼動できます。
その目的は、最初のサーバが故障したとき次のサーバへ速やかに引き継ぎができること（高可用性）および複数のコンピュータが同一のデータを処理できること（負荷分散）です。
データベースサーバがシームレスに共同稼動できれば理想的です。
静的なウェブページを提供するウェブサーバは、ウェブからの要求で生ずる負荷を複数のマシンに分散するだけで、簡単に結合できます。
実際、読み取り専用のデータベースサーバの結合は、同じようにかなり容易です。
しかし、大部分のデータベースサーバは、読み書きの混在した要求を受け取り、読み書き両用のサーバの結合はとても困難です。
なぜなら、読み取り要求だけの場合、全サーバへのデータの配布は1回で終わります。
しかし、書き込み後の読み取り要求に対して一貫性のある結果を返すためには、書き込み要求を受けたサーバだけでなく、他の全サーバにおいてもデータに書き込まなければなりません。
 </p><p><span class="original"><!--$-->
  This synchronization problem is the fundamental difficulty for
  servers working together.  Because there is no single solution
  that eliminates the impact of the sync problem for all use cases,
  there are multiple solutions.  Each solution addresses this
  problem in a different way, and minimizes its impact for a specific
  workload.
</span><br />この同時性を持たせるという問題は、共同して稼動するサーバにおいて根本的に困難なものです。
すべての使用状況において、単一の解法を用いて同時性の問題の影響を軽減できないため、複数の解法が存在します。
各々の解法はこの問題に異なったやり方を適用し、固有の作業負荷に対する影響を最小化します。
 </p><p><span class="original"><!--$-->
  Some solutions deal with synchronization by allowing only one
  server to modify the data.  Servers that can modify data are
  called read/write, &lt;firstterm&gt;master&lt;/&gt; or &lt;firstterm&gt;primary&lt;/&gt; servers.
  Servers that track changes in the master are called &lt;firstterm&gt;standby&lt;/&gt;
  or &lt;firstterm&gt;slave&lt;/&gt; servers. A standby server that cannot be connected
  to until it is promoted to a master server is called a &lt;firstterm&gt;warm
  standby&lt;/&gt; server, and one that can accept connections and serves read-only
  queries is called a &lt;firstterm&gt;hot standby&lt;/&gt; server.
</span><br />幾つかの解法では、1つのサーバだけにデータの更新を許可することにより、同時性を持たせています。
データの更新ができるサーバを、読み書きサーバ、<em class="firstterm">マスタ</em>サーバまたは<em class="firstterm">プライマリ</em>サーバといいます。
マスタの変更を追跡するサーバを、<em class="firstterm">スタンバイ</em>サーバまたは<em class="firstterm">スレーブ</em>サーバといいます。
マスタサーバに昇格するまで接続できないスタンバイサーバを<em class="firstterm">ウォームスタンバイ</em>サーバといいます。
接続を受理できて読み取り専用の問い合わせを処理できるスタンバイサーバを<em class="firstterm">ホットスタンバイ</em>サーバといいます。
 </p><p><span class="original"><!--$--> Changed-v1.29
  Some solutions are synchronous,
  meaning that a data-modifying transaction is not considered
  committed until all servers have committed the transaction.  This
  guarantees that a failover will not lose any data and that all
  load-balanced servers will return consistent results no matter
  which server is queried. In contrast, asynchronous solutions allow some
  delay between the time of a commit and its propagation to the other servers,
  opening the possibility that some transactions might be lost in
  the switch to a backup server, and that load balanced servers
  might return slightly stale results.  Asynchronous communication
  is used when synchronous would be too slow.
</span><br />いくつかの同期の解法が提供されています。
すなわち、データに書き込むトランザクションでは、全サーバがコミットするまでトランザクションはコミットされません。
これによって、フェールオーバにおいてデータの消失がないことが保証されます。
また、どのサーバが問い合わせを受理したかに関係なく、全ての負荷分散サーバが一貫した結果を返すことが保証されます。
それに対して非同期の解法では、コミット時刻と他サーバへの伝達時刻に時間差がありうるため、バックアップサーバへ交代する時にトランザクションが消失する可能性があります。
また、負荷分散サーバにおいては、最新でない結果を応答する可能性があります。
サーバ間の非同期の通信は、同期が非常に低速な場合に使用されます。
 </p><p><span class="original"><!--$-->
  Solutions can also be categorized by their granularity.  Some solutions
  can deal only with an entire database server, while others allow control
  at the per-table or per-database level.
</span><br />解法は粒度によって分類することもできます。
ある解法ではデータベースサーバ全体だけを範囲として処理しますが、他の解法では各テーブルまたは各データベースを範囲として管理できます。
 </p><p><span class="original"><!--$-->
  Performance must be considered in any choice.  There is usually a
  trade-off between functionality and
  performance.  For example, a fully synchronous solution over a slow
  network might cut performance by more than half, while an asynchronous
  one might have a minimal performance impact.
</span><br />すべての選択において、作業効率を考えなければなりません。
通常、作業効率と機能性は相反する関係にあります。
例えば、遅いネットワークの場合、完全同期の解法を使えば作業効率は半分以下となりますが、非同期の解法を使えば作業効率への影響が最小となります。
 </p><p><span class="original"><!--$-->
  The remainder of this section outlines various failover, replication,
  and load balancing solutions.  A &lt;ulink
  url="http://www.postgres-r.org/documentation/terms"&gt;glossary&lt;/ulink&gt; is
  also available.
</span><br />本節では、フェールオーバとレプリケーションと負荷分散における種々の解法を説明します。
<a class="ulink" href="http://www.postgres-r.org/documentation/terms" target="_top">glossary</a>も利用できます。
 </p><span class="original"><!--$-->
v.181でこのsect1の英文は削除
念のためコメントアウトし、本当の削除を保留
  &lt;sect1 id="backup-incremental-updated"&gt;

   &lt;title&gt;Incrementally Updated Backups&lt;/title&gt;

   &lt;title&gt;増分更新バックアップ&lt;/title&gt;

  &lt;indexterm zone="high-availability"&gt;
   &lt;primary&gt;incrementally updated backups&lt;/primary&gt;
  &lt;/indexterm&gt;

  &lt;indexterm zone="high-availability"&gt;
   &lt;primary&gt;change accumulation&lt;/primary&gt;
  &lt;/indexterm&gt;

   &lt;para&gt;

    In a standby configuration, it is possible to offload the expense of
    taking periodic base backups from the primary server; instead base backups
    can be made by backing
    up a standby server's files.  This concept is generally known as
    incrementally updated backups, log change accumulation, or more simply,
    change accumulation.

スタンバイ設定では、プライマリサーバから定期的なベースバックアップを取るための必要コストを軽減することができます。
代わりにベースバックアップはスタンバイサーバのファイルをバックアップすることで作成することができます。
通常この概念は、増分更新バックアップ、ログ変更蓄積、または単に変更蓄積として知られています。
   &lt;/para&gt;

   &lt;para&gt;

    If we take a file system backup of the standby server's data
    directory while it is processing
    logs shipped from the primary, we will be able to reload that backup and
    restart the standby's recovery process from the last restart point.
    We no longer need to keep WAL files from before the standby's restart point.
    If recovery is needed, it will be faster to recover from the incrementally
    updated backup than from the original base backup.

プライマリから転送されるログを処理しつつスタンバイサーバのデータディレクトリのファイルシステムバックアップを取得する場合、バックアップを再ロードし、スタンバイのリカバリ処理を最終リスタートポイントから再起動させることができます。
リスタートポイント以前の WAL ファイルは、もはや保存しなくてかまいません。
リカバリが必要な場合、増分更新バックアップからの復旧は、元のベースバックアップからの復旧より早くなります。
   &lt;/para&gt;

   &lt;para&gt;

    The procedure for taking a file system backup of the standby server's
    data directory while it's processing logs shipped from the primary is:

プライマリサーバから転送されるログを処理しつつスタンバイサーバのデータディレクトリのファイルシステムバックアップを取得する手順は以下です。
   &lt;orderedlist&gt;
    &lt;listitem&gt;
     &lt;para&gt;

      Perform the backup, without using &lt;function&gt;pg_start_backup&lt;/&gt; and
      &lt;function&gt;pg_stop_backup&lt;/&gt;. Note that the &lt;filename&gt;pg_control&lt;/&gt;
      file must be backed up &lt;emphasis&gt;first&lt;/&gt;, as in:

&lt;function&gt;pg_start_backup&lt;/&gt;と&lt;function&gt;pg_stop_backup&lt;/&gt;を使用しないでバックアップを行います。
下記のように、&lt;filename&gt;pg_control&lt;/&gt;を&lt;emphasis&gt;最初に&lt;/&gt;バックアップしなければならないことに注意してください。
&lt;programlisting&gt;
cp /var/lib/pgsql/data/global/pg_control /tmp
cp -r /var/lib/pgsql/data /path/to/backup
mv /tmp/pg_control /path/to/backup/data/global
&lt;/programlisting&gt;

      &lt;filename&gt;pg_control&lt;/&gt; contains the location where WAL replay will
      begin after restoring from the backup; backing it up first ensures
      that it points to the last restartpoint when the backup started, not
      some later restartpoint that happened while files were copied to the
      backup.

&lt;filename&gt;pg_control&lt;/&gt;には、バックアップからリストアした後に再生を始めるWAL位置が含まれています。
まずこのファイルをバックアップすることで、ファイルをコピーしている間に発生する多少遅れたリスタートポイントではなく、バックアップを始めた時の最終リスタートポイントを指し示していることを確実にします。
     &lt;/para&gt;
    &lt;/listitem&gt;
    &lt;listitem&gt;
     &lt;para&gt;

      Make note of the backup ending WAL location by calling the &lt;function&gt;
      pg_last_xlog_replay_location&lt;/&gt; function at the end of the backup,
      and keep it with the backup.

バックアップの終了時に&lt;function&gt;pg_last_xlog_replay_location&lt;/&gt;関数を呼び出すことにより、バックアップ終了時点のWAL位置を採取して保存してください。
&lt;programlisting&gt;
psql -c "select pg_last_xlog_replay_location();" &amp;gt; /path/to/backup/end_location
&lt;/programlisting&gt;

      When recovering from the incrementally updated backup, the server
      can begin accepting connections and complete the recovery successfully
      before the database has become consistent. To avoid that, you must
      ensure the database is consistent before users try to connect to the
      server and when the recovery ends. You can do that by comparing the
      progress of the recovery with the stored backup ending WAL location:
      the server is not consistent until recovery has reached the backup end
      location. The progress of the recovery can also be observed with the
      &lt;function&gt;pg_last_xlog_replay_location&lt;/&gt; function, but that required
      connecting to the server while it might not be consistent yet, so
      care should be taken with that method.

増分更新バックアップからリカバリする場合、一貫性を持つデータベースになる前に、サーバは接続を受け付けることも、リカバリを正常に完了することもあり得ます。
これを防止するためには、ユーザがサーバに接続しようとする前、および、リカバリが終わった時に整合性を持つデータベースであることを確実にしなければなりません。
リカバリの進行と保管されたバックアップ終了時のWAL位置とを比較することで、これを実現できます。
リカバリがバックアップ終了時のWAL位置に達するまで、サーバは整合性を持ちません。
リカバリの進行は&lt;function&gt;pg_last_xlog_replay_location&lt;/&gt;関数を用いて確認することができます。
しかし、これには、まだ整合性を持たないかもしれないデータベースに接続しなければなりません。
このためこの方法を行う時には注意しなければなりません。
     &lt;para&gt;
     &lt;/para&gt;
    &lt;/listitem&gt;
   &lt;/orderedlist&gt;
   &lt;/para&gt;

   &lt;para&gt;

    Since the standby server is not &lt;quote&gt;live&lt;/&gt;, it is not possible to
    use &lt;function&gt;pg_start_backup()&lt;/&gt; and &lt;function&gt;pg_stop_backup()&lt;/&gt;
    to manage the backup process; it will be up to you to determine how
    far back you need to keep WAL segment files to have a recoverable
    backup. That is determined by the last restartpoint when the backup
    was taken, any WAL older than that can be deleted from the archive
    once the backup is complete. You can determine the last restartpoint
    by running &lt;application&gt;pg_controldata&lt;/&gt; on the standby server before
    taking the backup, or by using the &lt;varname&gt;log_checkpoints&lt;/&gt; option
    to print values to the standby's server log.

スタンバイサーバは&lt;quote&gt;活動中&lt;/&gt;ではありませんので、&lt;function&gt;pg_start_backup()&lt;/&gt;と&lt;function&gt;pg_stop_backup()&lt;/&gt;を使用してバックアップ処理を管理することはできません。
リカバリ可能なバックアップを持つためにWALセグメントをどれだけ維持しなければならないか決定することは管理者の責任です。
バックアップを取得した時点の最終リスタートポイントによって決定されます。
これより古いWALはバックアップが完了した後にアーカイブから削除することができます。
バックアップを取得する前にスタンバイサーバで&lt;application&gt;pg_controldata&lt;/&gt;を実行すること、または、スタンバイサーバのログに値を出力する&lt;varname&gt;log_checkpoints&lt;/&gt;オプションを使用することにより、最終リスタートポイントを決定することができます。
   &lt;/para&gt;
  &lt;/sect1&gt;
コメントアウト終わり
</span><br /></div><div class="navfooter"><hr /><table width="100%" summary="Navigation footer"><tr><td width="40%" align="left"><a accesskey="p" href="continuous-archiving.html">戻る</a> </td><td width="20%" align="center"><a accesskey="u" href="admin.html">上に戻る</a></td><td width="40%" align="right"> <a accesskey="n" href="different-replication-solutions.html">次へ</a></td></tr><tr><td width="40%" align="left" valign="top">24.3. 継続的アーカイブとポイントインタイムリカバリ（PITR） </td><td width="20%" align="center"><a accesskey="h" href="index.html">ホーム</a></td><td width="40%" align="right" valign="top"> 25.1. 様々な解法の比較</td></tr></table></div></body></html>